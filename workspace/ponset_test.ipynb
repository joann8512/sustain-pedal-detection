{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742d63da-69c7-484d-9336-d1a0c776b756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os, sys, argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import medfilt\n",
    "from builtins import range\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "import mir_eval\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Flatten, Input, Reshape, Dropout, Permute\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c29d91b1-44fe-41ba-9b04-4d48f23a4dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel-last, i.e., (None, n_freq, n_time, n_ch)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # the number of the GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3 # percentage to be used\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from global_config import *\n",
    "\n",
    "reg_w = 1e-4\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c9ec44-d1f3-45a8-aecd-8a9bcad71718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(audio_data, n_detect, nsp_excerpt, type_excerpt, hop_length=HOP_LENGTH):\n",
    "    \"\"\"Data generator.\n",
    "    excerpt: data of one audio file.\n",
    "    n_detect: number of excerpts to be detected.\n",
    "    nsp_detect: number of samples in one excerpt.\n",
    "    \"\"\"\n",
    "    \n",
    "    tile_times = int(np.ceil(NSP_SRC/nsp_excerpt))\n",
    "\n",
    "    while True:\n",
    "        for i in range(n_detect):\n",
    "            \n",
    "            if type_excerpt == 'onset':\n",
    "                src_batch = np.array([audio_data[int(i*hop_length):int(i*hop_length+nsp_excerpt)]], dtype=K.floatx())\n",
    "            elif type_excerpt == 'segment':\n",
    "                src_batch = np.array([np.tile(audio_data[int(i*hop_length):int(i*hop_length+nsp_excerpt)],tile_times)[:NSP_SRC]],\n",
    "                                     dtype=K.floatx())\n",
    "                \n",
    "            src_batch = src_batch[:, np.newaxis, :]  # make (batch, N) to (batch, 1, N) for kapre compatible\n",
    "            \n",
    "            yield src_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a245a9f-9f75-4fc6-8e37-aa5ebb14f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervals1tointervals01(segintervals1, paudio_duration):\n",
    "    idx2del = []\n",
    "    for idx in np.arange(1,len(segintervals1)):\n",
    "        if segintervals1[idx-1][1] >= segintervals1[idx][0]:\n",
    "            segintervals1[idx] = [segintervals1[idx-1][0],segintervals1[idx][1]]\n",
    "            idx2del.append(idx-1)           \n",
    "    segintervals1 = np.delete(segintervals1, idx2del, axis=0)  \n",
    "    \n",
    "    labels = []\n",
    "    segintervals01 = np.zeros((len(segintervals1)*2+1,2))\n",
    "    \n",
    "    for idx in range(len(segintervals01)):\n",
    "        if idx==0:\n",
    "            segintervals01[idx] = [0, segintervals1[0][0]]\n",
    "            labels.append('np')\n",
    "        elif idx==len(segintervals01)-1:\n",
    "            segintervals01[idx] = [segintervals1[-1][-1],paudio_duration]\n",
    "            labels.append('np')\n",
    "        elif idx%2:\n",
    "            segintervals01[idx] = segintervals1[int(np.floor(idx/2))]\n",
    "            labels.append('p')\n",
    "        else:\n",
    "            segintervals01[idx] = [segintervals1[int(np.floor(idx/2)-1)][-1],segintervals1[int(np.floor(idx/2))][0]]\n",
    "            labels.append('np')\n",
    "            \n",
    "    idx2del = []\n",
    "    for idx, seginterval in enumerate(segintervals01):\n",
    "        if seginterval[0]==seginterval[1]:\n",
    "            idx2del.append(idx)\n",
    "    segintervals01 = np.delete(segintervals01, idx2del, axis=0)\n",
    "    labels = np.delete(labels, idx2del)\n",
    "    \n",
    "    return segintervals1, segintervals01, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "346a50fa-b3dc-469c-b735-1ed1409b2cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_type = 'real'\n",
    "onset_threshold = 0.98\n",
    "segment_threshold = 0.98\n",
    "input_type = 'melspectrogram'\n",
    "\n",
    "dataset_name = 'pedal-times_maestro.npz'\n",
    "npz_path = os.path.join(DIR_PEDAL_METADATA, dataset_name)\n",
    "\n",
    "tracks = np.load(npz_path, allow_pickle=True)\n",
    "t_tracks = tracks['category'] == 'test'\n",
    "test = [i for i, x in enumerate(t_tracks) if x]\n",
    "\n",
    "filenames = tracks['filename'][test]\n",
    "pedal_offset_gt_tracks = tracks['pedal_offset'][test]\n",
    "pedal_onset_gt_tracks = tracks['pedal_onset'][test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c20c199b-d026-4f16-86a2-0def150370fa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jching9/miniconda3/envs/susPed/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "tracking <tf.Variable 'melspectrogram_1/real_kernels:0' shape=(1024, 1, 1, 513) dtype=float32> dft_real_kernels\n",
      "tracking <tf.Variable 'melspectrogram_1/imag_kernels:0' shape=(1024, 1, 1, 513) dtype=float32> dft_imag_kernels\n",
      "tracking <tf.Variable 'melspectrogram_1/Variable:0' shape=(513, 128) dtype=float32> freq2mel\n",
      "WARNING:tensorflow:From /home/jching9/miniconda3/envs/susPed/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jching9/miniconda3/envs/susPed/lib/python3.6/site-packages/librosa/filters.py:196: FutureWarning: norm=1 behavior will change in librosa 0.8.0. To maintain forward compatibility, use norm='slaney' instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jching9/miniconda3/envs/susPed/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/jching9/miniconda3/envs/susPed/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "tracking <tf.Variable 'melspectrogram_1_1/real_kernels:0' shape=(1024, 1, 1, 513) dtype=float32> dft_real_kernels\n",
      "tracking <tf.Variable 'melspectrogram_1_1/imag_kernels:0' shape=(1024, 1, 1, 513) dtype=float32> dft_imag_kernels\n",
      "tracking <tf.Variable 'melspectrogram_1_1/Variable:0' shape=(513, 128) dtype=float32> freq2mel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jching9/miniconda3/envs/susPed/lib/python3.6/site-packages/librosa/filters.py:196: FutureWarning: norm=1 behavior will change in librosa 0.8.0. To maintain forward compatibility, use norm='slaney' instead.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "onset_exp_name = 'onset_multi_kernel_0123-2140'\n",
    "onset_model = keras.models.load_model(os.path.join(DIR_SAVE_MODEL,\"{}_best_model.h5\".format(onset_exp_name)),\n",
    "                                      custom_objects={'Melspectrogram':Melspectrogram})\n",
    "onset_model.load_weights(os.path.join(DIR_SAVE_MODEL,\"{}_best_weights.h5\".format(onset_exp_name)))    \n",
    "#segment_exp_name = 'sub-segment_cnnkernel-melspectrogram_multift'\n",
    "segment_exp_name = 'small-segment_multi_kernel'\n",
    "segment_model = keras.models.load_model(os.path.join(DIR_SAVE_MODEL,\"{}_best_model.h5\".format(segment_exp_name)),\n",
    "                                        custom_objects={'Melspectrogram':Melspectrogram})\n",
    "segment_model.load_weights(os.path.join(DIR_SAVE_MODEL,\"{}_best_weights.h5\".format(segment_exp_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "951af9ea-1aad-490a-baaa-0e930d99d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise performance measurement\n",
    "filename_records = []\n",
    "accuracys = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "support0s = []\n",
    "support1s = []\n",
    "fp_rates = []\n",
    "fn_rates = []\n",
    "# append to lists\n",
    "filename_records = []\n",
    "support0s = []\n",
    "support1s = []\n",
    "acc01_frms = []\n",
    "p1_frms = []\n",
    "r1_frms = []\n",
    "f1_frms = []\n",
    "fp_rates = []\n",
    "fn_rates = []\n",
    "# boundary matrixs\n",
    "boundary_wins = []\n",
    "p1_sbrs = []\n",
    "r1_sbrs = []\n",
    "f1_sbrs = []\n",
    "r2e_deviation1s = []\n",
    "e2r_deviation1s = []\n",
    "p01_sbrs = []\n",
    "r01_sbrs = []\n",
    "f01_sbrs = []\n",
    "r2e_deviation01s = []\n",
    "e2r_deviation01s = []\n",
    "# structural matrixs\n",
    "p_pairwises = []\n",
    "r_pairwises = []\n",
    "f_pairwises = []\n",
    "nce_overs = []\n",
    "nce_unders = []\n",
    "nce_fs = []\n",
    "rand_indexs = []\n",
    "adjrand_indexs = []\n",
    "mutual_infos = []\n",
    "adjmutual_infos = []\n",
    "normmutual_infos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e453b639-d303-44bd-950f-46aa8b166ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:  2018/MIDI-Unprocessed_Recital13-15_MID--AUDIO_15_R1_2018_wav--1.wav\n",
      "2018/MIDI-Unprocessed_Recital13-15_MID--AUDIO_15_R1_2018_wav--1.wav...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All interval durations must be strictly positive",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d36ace1b79f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mr2e_deviation1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2r_deviation1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmir_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeviation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegintervals1_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegintervals1_est\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# performance matrix based on boundary annotation of both 'p' and 'np'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mp01_sbr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr01_sbr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf01_sbr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmir_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegintervals01_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegintervals01_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeat_insecond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# performance matrix based on structural annotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/susPed/lib/python3.6/site-packages/mir_eval/segment.py\u001b[0m in \u001b[0;36mdetection\u001b[0;34m(reference_intervals, estimated_intervals, window, beta, trim)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \"\"\"\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mvalidate_boundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_intervals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimated_intervals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;31m# Convert intervals to boundaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/susPed/lib/python3.6/site-packages/mir_eval/segment.py\u001b[0m in \u001b[0;36mvalidate_boundary\u001b[0;34m(reference_intervals, estimated_intervals, trim)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mintervals\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreference_intervals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimated_intervals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_intervals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintervals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/susPed/lib/python3.6/site-packages/mir_eval/util.py\u001b[0m in \u001b[0;36mvalidate_intervals\u001b[0;34m(intervals)\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Make sure all intervals have strictly positive duration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mintervals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mintervals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All interval durations must be strictly positive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: All interval durations must be strictly positive"
     ]
    }
   ],
   "source": [
    "for filename_idx, filename in enumerate(filenames):  \n",
    "    print('filename: ', filename)\n",
    "    # load ground truth of the current piece \n",
    "    pedal_offset_gt = np.array(pedal_offset_gt_tracks[filename_idx])\n",
    "    pedal_onset_gt = np.array(pedal_onset_gt_tracks[filename_idx])\n",
    "\n",
    "    # load audio data of the current piece\n",
    "    paudio_dir = os.path.join(DIR_REAL_DATA, '{}'.format(filename)) \n",
    "    #print(paudio_dir)\n",
    "    #paudio_path = paudio_dir + '.wav'\n",
    "    #print(paudio_path)\n",
    "    paudio, sr = librosa.load(paudio_dir, sr=SR) \n",
    "    print(\"{}...\".format(filename))\n",
    "\n",
    "    # detect pedal onset if threshold is greater than 0\n",
    "    if onset_threshold>0:\n",
    "        len_onset_shape = int(SR * (TRIM_SECOND_BEFORE + TRIM_SECOND_AFTER))\n",
    "        onsethop_length = HOP_LENGTH\n",
    "        onsethop_duration = onsethop_length/SR\n",
    "        n_ponset = int(np.ceil((len(paudio)-len_onset_shape)/onsethop_length))\n",
    "        gen_ponset = data_gen(paudio, n_ponset, len_onset_shape, 'onset', hop_length=onsethop_length)\n",
    "        pred_ponset = onset_model.predict_generator(gen_ponset, n_ponset // batch_size)\n",
    "        # filter to reduce fragmentation\n",
    "        pred_ponset_filter = medfilt(pred_ponset[:,1],15)\n",
    "        # the corresponding time in second each frame represents\n",
    "        frmtime_ponset = np.arange(n_ponset)*onsethop_duration+TRIM_SECOND_BEFORE\n",
    "        # represent as frame wise binary results\n",
    "        pred_ponset_todetect = np.copy(pred_ponset_filter)\n",
    "        pred_ponset_todetect[pred_ponset_todetect<onset_threshold]=0\n",
    "        pred_ponset_todetect[pred_ponset_todetect>=onset_threshold]=1\n",
    "\n",
    "    # detect pedalled segment\n",
    "    len_segment_shape = int(SR * MIN_SRC)\n",
    "    seghop_length = HOP_LENGTH*10\n",
    "    seghop_duration = seghop_length/SR\n",
    "    n_psegment = int(np.ceil((len(paudio)-len_segment_shape)/seghop_length))\n",
    "    gen_psegment = data_gen(paudio, n_psegment, len_segment_shape, 'segment', hop_length=seghop_length)\n",
    "    pred_psegment = segment_model.predict_generator(gen_psegment, n_psegment // batch_size)\n",
    "    # filter to reduce fragmentation\n",
    "    pred_psegment_filter = medfilt(pred_psegment[:,1],3)\n",
    "    # the corresponding time in second each frame represents\n",
    "    frmtime_psegment = np.arange(n_psegment)*seghop_duration+MIN_SRC/2\n",
    "    # remove the predicted value before the note onset\n",
    "    paudio_firstonsettime = librosa.frames_to_time(librosa.onset.onset_detect(y=paudio, sr=SR), sr=SR)[0]\n",
    "    n_segment_tozero=0\n",
    "    for t in frmtime_psegment:\n",
    "        if t < paudio_firstonsettime:\n",
    "            n_segment_tozero+=1\n",
    "        else:\n",
    "            break        \n",
    "    pred_psegment_filter[:n_segment_tozero] = 0\n",
    "    # represent as frame wise binary results\n",
    "    pred_psegment_todetect = np.copy(pred_psegment_filter)\n",
    "    pred_psegment_todetect[pred_psegment_todetect<segment_threshold]=0\n",
    "    pred_psegment_todetect[pred_psegment_todetect>=segment_threshold]=1\n",
    "\n",
    "    # decide the initial indexes of pedal segment boundary\n",
    "    onseg_initidxs = []\n",
    "    offseg_initidxs = []\n",
    "    for idx, v in enumerate(pred_psegment_todetect):\n",
    "        if idx>0 and idx<len(pred_psegment_todetect)-1:\n",
    "            if pred_psegment_todetect[idx-1]==0 and v==1 and pred_psegment_todetect[idx+1]==1:\n",
    "                onseg_initidxs.append(idx-1)\n",
    "            elif pred_psegment_todetect[idx-1]==1 and v==1 and pred_psegment_todetect[idx+1]==0:\n",
    "                offseg_initidxs.append(idx+1)\n",
    "\n",
    "    if offseg_initidxs[0] <= onseg_initidxs[0]:\n",
    "        del offseg_initidxs[0]\n",
    "    if onseg_initidxs[-1] >= offseg_initidxs[-1]:\n",
    "        del onseg_initidxs[-1]\n",
    "\n",
    "    if (len(onseg_initidxs) != len(offseg_initidxs)) or not len(pedal_offset_gt) or not len(pedal_onset_gt):\n",
    "        print(\" skip!\")\n",
    "    else:\n",
    "        onseg_idxs = []\n",
    "        offseg_idxs = []\n",
    "        for idx in range(len(onseg_initidxs)):\n",
    "            if onseg_initidxs[idx] < offseg_initidxs[idx]:\n",
    "                onseg_idxs.append(onseg_initidxs[idx])\n",
    "                offseg_idxs.append(offseg_initidxs[idx])\n",
    "\n",
    "        if not len(onseg_idxs) or not len(offseg_idxs):\n",
    "            print(\"  no detection!\")  \n",
    "\n",
    "        else:\n",
    "            if onset_threshold>0:\n",
    "                # decide the boundary times in seconds with pedal onset candidates\n",
    "                onseg_times = []\n",
    "                offseg_times = []\n",
    "                for idx, onseg_idx in enumerate(onseg_idxs):\n",
    "                    onponset_idx = onseg_idx*10-5\n",
    "                    if any(pred_ponset_todetect[onponset_idx-5:onponset_idx+5]):\n",
    "                        offseg_idx = offseg_idxs[idx]\n",
    "                        offseg_times.append(frmtime_psegment[offseg_idx])\n",
    "                        onseg_times.append(frmtime_psegment[onseg_idx])\n",
    "            else:\n",
    "                onseg_times = frmtime_psegment[onseg_idxs] \n",
    "                offseg_times = frmtime_psegment[offseg_idxs]\n",
    "\n",
    "            segintervals_est = np.stack((np.asarray(onseg_times),np.asarray(offseg_times)), axis=-1)\n",
    "\n",
    "            # set the ground truth and estimation results frame by frame\n",
    "            paudio_duration = librosa.get_duration(y=paudio, sr=SR)\n",
    "            n_frames = int(np.ceil(paudio_duration/seghop_duration))\n",
    "            segframes_gt = np.zeros(n_frames)\n",
    "            segframes_est = np.zeros(n_frames)\n",
    "\n",
    "            pedal_offset_gt = np.array(tracks['pedal_offset'][filename_idx])\n",
    "            pedal_onset_gt = np.array(tracks['pedal_onset'][filename_idx])\n",
    "            longpseg_idx = np.where((pedal_offset_gt-pedal_onset_gt)>seghop_duration)[0]\n",
    "            longseg_onset_gt = pedal_onset_gt[longpseg_idx]\n",
    "            longseg_offset_gt = pedal_offset_gt[longpseg_idx]\n",
    "            segintervals_gt = np.stack((longseg_onset_gt,longseg_offset_gt), axis=-1)\n",
    "\n",
    "            for idx, onset_t in enumerate(longseg_onset_gt):\n",
    "                offset_t = longseg_offset_gt[idx]\n",
    "                onset_frm = int(onset_t//seghop_duration)\n",
    "                offset_frm = int(offset_t//seghop_duration)\n",
    "                segframes_gt[onset_frm:offset_frm] = 1\n",
    "\n",
    "            for idx, onset_t in enumerate(onseg_times):\n",
    "                offset_t = offseg_times[idx]\n",
    "                onset_frm = int(onset_t//seghop_duration)\n",
    "                offset_frm = int(offset_t//seghop_duration)\n",
    "                segframes_est[onset_frm:offset_frm] = 1 \n",
    "\n",
    "            # set the ground truth and estimation results as interval format\n",
    "            segintervals1_gt, segintervals01_gt, labels_gt = intervals1tointervals01(segintervals_gt, paudio_duration)\n",
    "            segintervals1_est, segintervals01_est, labels_est = intervals1tointervals01(segintervals_est, paudio_duration)\n",
    "\n",
    "            # Metrics for frame-wise label 'p'\n",
    "            acc01_frm = accuracy_score(segframes_gt,segframes_est)\n",
    "            p1_frm, r1_frm, f1_frm, support = precision_recall_fscore_support(segframes_gt,segframes_est)\n",
    "            tn, fp, fn, tp = confusion_matrix(segframes_gt,segframes_est).ravel()\n",
    "            fp_rate = fp/(fp+tn)\n",
    "            fn_rate = fn/(fn+tp)\n",
    "\n",
    "            # performance matrix based on boundary annotation of 'p'\n",
    "            # window depends on duration of a beat\n",
    "            onset_env = librosa.onset.onset_strength(paudio, sr=SR)\n",
    "            tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=SR)[0]\n",
    "            beat_insecond = 60/tempo\n",
    "            p1_sbr,r1_sbr,f1_sbr = mir_eval.segment.detection(segintervals1_gt, segintervals1_est, window=beat_insecond)\n",
    "            r2e_deviation1, e2r_deviation1 = mir_eval.segment.deviation(segintervals1_gt, segintervals1_est)\n",
    "            # performance matrix based on boundary annotation of both 'p' and 'np' \n",
    "            p01_sbr,r01_sbr,f01_sbr = mir_eval.segment.detection(segintervals01_gt, segintervals01_est, window=beat_insecond)\n",
    "\n",
    "            # performance matrix based on structural annotation\n",
    "            scores = mir_eval.segment.evaluate(segintervals01_gt, labels_gt, segintervals01_est, labels_est)\n",
    "            r2e_deviation01, e2r_deviation01 = [scores['Ref-to-est deviation'], scores['Est-to-ref deviation']]\n",
    "            p_pairwise, r_pairwise, f_pairwise = [scores['Pairwise Precision'], scores['Pairwise Recall'], \n",
    "                                                  scores['Pairwise F-measure']]\n",
    "            rand_index, adjrand_index = [scores['Rand Index'], scores['Adjusted Rand Index']]\n",
    "            mutual_info, adjmutual_info, normmutual_info = [scores['Mutual Information'], scores['Adjusted Mutual Information'], \n",
    "                                                            scores['Normalized Mutual Information']]\n",
    "            nce_over, nce_under, nce_f = [scores['NCE Over'], scores['NCE Under'], scores['NCE F-measure']]\n",
    "\n",
    "            # append to lists\n",
    "            filename_records.append(filename)\n",
    "            support0s.append(support[0])\n",
    "            support1s.append(support[1])\n",
    "            acc01_frms.append(acc01_frm)\n",
    "            p1_frms.append(p1_frm[1])\n",
    "            r1_frms.append(r1_frm[1])\n",
    "            f1_frms.append(f1_frm[1])\n",
    "            fp_rates.append(fp_rate)\n",
    "            fn_rates.append(fn_rate)\n",
    "            # boundary matrixs\n",
    "            boundary_wins.append(beat_insecond)\n",
    "            p1_sbrs.append(p1_sbr)\n",
    "            r1_sbrs.append(r1_sbr)\n",
    "            f1_sbrs.append(f1_sbr)\n",
    "            r2e_deviation1s.append(r2e_deviation1)\n",
    "            e2r_deviation1s.append(e2r_deviation1)\n",
    "            p01_sbrs.append(p01_sbr)\n",
    "            r01_sbrs.append(r01_sbr)\n",
    "            f01_sbrs.append(f01_sbr)\n",
    "            r2e_deviation01s.append(r2e_deviation01)\n",
    "            e2r_deviation01s.append(e2r_deviation01)\n",
    "            # structural matrixs\n",
    "            p_pairwises.append(p_pairwise)\n",
    "            r_pairwises.append(r_pairwise)\n",
    "            f_pairwises.append(f_pairwise)\n",
    "            nce_overs.append(nce_over)\n",
    "            nce_unders.append(nce_under)\n",
    "            nce_fs.append(nce_f)\n",
    "            rand_indexs.append(rand_index)\n",
    "            adjrand_indexs.append(adjrand_index)\n",
    "            mutual_infos.append(mutual_info)\n",
    "            adjmutual_infos.append(adjmutual_info)\n",
    "            normmutual_infos.append(normmutual_info)\n",
    "            print(\"  done!\")\n",
    "\n",
    "rows = zip(*[filename_records, support0s, support1s, acc01_frms, p1_frms, r1_frms, f1_frms, fp_rates, fn_rates, \n",
    "             boundary_wins, p1_sbrs, r1_sbrs, f1_sbrs, r2e_deviation1s, e2r_deviation1s,\n",
    "             p01_sbrs, r01_sbrs, f01_sbrs, r2e_deviation01s, e2r_deviation01s,\n",
    "             p_pairwises, r_pairwises, f_pairwises, nce_overs, nce_unders, nce_fs, rand_indexs, \n",
    "             adjrand_indexs, mutual_infos, adjmutual_infos, normmutual_infos])\n",
    "column_names =  ['filename_record', 'support0', 'support1', 'acc01_frm', 'p1_frm', 'r1_frm', 'f1_frm', 'fp_rate', 'fn_rate', \n",
    "                 'boundary_win', 'p1_sbr', 'r1_sbr', 'f1_sbr', 'r2e_deviation1', 'e2r_deviation1',\n",
    "                 'p01_sbr', 'r01_sbr', 'f01_sbr', 'r2e_deviation01', 'e2r_deviation01',\n",
    "                 'p_pairwise', 'r_pairwise', 'f_pairwise', 'nce_over', 'nce_under', 'nce_f', 'rand_index', \n",
    "                 'adjrand_index', 'mutual_info', 'adjmutual_info', 'normmutual_info']\n",
    "df = pd.DataFrame(rows, columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c3d012-8bef-4cfc-a33f-6aecee5eca32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "susPed",
   "language": "python",
   "name": "susped"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
